
1. Web Page categorization
Most important and challenging task of this project is categorization of web page according to textual content. Classifying website according to textual content will not give much accuracy because of inclusion of several multimedia items in web pages. However it will let us to categorize web pages with a certain accuracy. In this project , we will use k-nearest neighbours algorithm for classification.
The first step in web page categorization is to transform web page which is usually strings of characters into a form suitable for learning algorithm. Some words in web page with extra power (words included in tags like <head>, <title>, <strong>, <b>...etc) will be given deserving weight-age. The most commonly used document representation is the so-called vector space model. In this model, each document is represented by a vector of words. A word-by-document matrix A is used for a collection of documents, where each entry represents the occurrence of a word in a document, i.e., A=(aij), where aij is the weight of word i in document j. There are several ways of determining the weight aij. Let fij be the frequency of word i in document j, N the number of documents in the collection, M the number of distinct words in the collection, and ni the total number of times word i occurs in the whole collection. The simplest approach is Boolean weighting, which sets the weight aij to 1 if the word occurs in the document and 0 otherwise. Another simple approach uses the frequency of the word in the document, i.e., aij=fij . A more common weighting approach is the so-called tf -idf (term frequency - inverse document frequency) weighting: 

A slight variation of the tf -idf weighting, which takes into account that documents may be of different lengths, is the following:

 

For matrix A, the number of rows corresponds to the number of words M in the document collection. There could be hundreds of thousands of different words. In order to reduce the high dimensionality, stop-word (frequent word that carries no information) removal, word stemming (suffix removal) and additional dimensionality reduction techniques, feature selection or re-parameterization, are usually employed. 
To classify a class-unknown document X, the k-Nearest Neighbor classifier algorithm ranks the document's neighbors among the training document vectors, and uses the class labels of the k most similar neighbors to predict the class of the new document. The classes of these neighbors are weighted using the similarity of each neighbor to X, where similarity is measured by Euclidean distance or the cosine value between two document vectors. The cosine similarity is defined as follows:
 
where X is the test document, represented as a vector; Dj is the jth training document; ti is a word shared by X and Dj; xi is the weight of word ti in X; dij is the weight of word ti in document Dj;  is the norm of X, and  is the norm of Dj. A cutoff threshold is needed to assign the new document to a known class.
2.Implementation Details
